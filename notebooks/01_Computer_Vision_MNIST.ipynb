{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ATENCIÓN:** Executar la siguiente celda solamente si se esta corriendo este notebook desde Google Colab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mNtpF18xNZIs"
   },
   "outputs": [],
   "source": [
    "# this mounts your Google Drive to the Colab VM.\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive', force_remount=True)\n",
    "\n",
    "# enter the foldername in your Drive where you have saved the unzipped\n",
    "# assignment folder, e.g. 'dlvis/assignments/assignment2/'\n",
    "FOLDERNAME = None\n",
    "assert FOLDERNAME is not None, \"[!] Enter the foldername.\"\n",
    "\n",
    "# now that we've mounted your Drive, this ensures that\n",
    "# the Python interpreter of the Colab VM can load\n",
    "# python files from within it.\n",
    "import sys\n",
    "sys.path.append('/content/drive/My Drive/{}'.format(FOLDERNAME))\n",
    "\n",
    "# this downloads the CIFAR-10 dataset to your Drive\n",
    "# if it doesn't already exist.\n",
    "%cd drive/My\\ Drive/$FOLDERNAME/cs231n/datasets/\n",
    "!bash get_datasets.sh\n",
    "%cd /content/drive/My\\ Drive/$FOLDERNAME"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lt0srYHUNZIz",
    "tags": [
     "pdf-title"
    ]
   },
   "source": [
    "# Computer Vision MNIST\n",
    "\n",
    "En este notebook se abordaran algunas de las funcionalidades básicas de Keras y Tensorflow, necesarias para cargar un dataset en memoria, definir la arquitectura de una Red Neuronal y posteriormente entrenarla para luego utiizarla en la inferencia de algunas imágenes.\n",
    "\n",
    "A su vez, la redes neuronales utilizan vectores de numpy por lo que veremos como se representa una imagen como vector de numpy y que propiedades tiene."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7DkxZtF3NZI6",
    "tags": [
     "pdf-ignore"
    ]
   },
   "source": [
    "# Tabla de Contenidos\n",
    "\n",
    "Este notebook contiene 5 partes. Vamos a repasar algunas funcionalidades básicas de TensorFlow y Keras entrenando un modelo para reconocer dígitos escritos a mano.\n",
    "\n",
    "1. Parte I, Preparación: cargar dataset MNIST.\n",
    "2. Parte II, Entendimiento: visualizar datos y obtener algunas estadísticas.\n",
    "3. Parte III, Entrenamiento: definición y entrenamiento de modelo.\n",
    "4. Parte IV, Evaluación: evaluar el modelo y predecir algunos casos.\n",
    "5. Pate V, Experimentación: Algunas opciones como Dropout y Optimizadores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TxYL1sA5NZI7"
   },
   "source": [
    "# Parte I: Preparación\n",
    "\n",
    "Primero, vamos a descargar el dataset MNIST. Esto puede tomar algunos minutos para descargar los datos por primer vez, pero luego de que los archivos son descargados y cacheados en disco la carga debería ser más rápida.\n",
    "\n",
    "Si bien es común trabajar con un dataset particular, por simplicidad vamos a trabajar un poco con el módulo ```tf.keras.datasets``` que ya provee utilidades para cargar y trabajar con cualquiera de los siguiente datasets clásicos:\n",
    "\n",
    "* MNIST digits classification\n",
    "* CIFAR10 small images classification\n",
    "* CIFAR100 small images classification\n",
    "* IMDB movie review sentiment classification\n",
    "* Reuters newswire classification\n",
    "* Fashion MNIST\n",
    "* Boston Housing price reression\n",
    "\n",
    "En este taller vamos a utilizar los datasts MNIST y CIFAR100. Por más información acerca de etos datasets leer el siguiente [link](https://keras.io/api/datasets/).\n",
    "\n",
    "Por otro lado, TensorFlow cuenta con el módulo `tf.data` para cargar un dataset cualquiera a partir de archivos CSV o un directorio de imágenes. Por más información referise al siguiente [link](https://www.tensorflow.org/guide/data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tTfjivr-NZI8",
    "tags": [
     "pdf-ignore"
    ]
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import math\n",
    "import timeit\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_mnist(num_training=58000, num_validation=2000, num_test=10000):\n",
    "    \"\"\"\n",
    "    Fetch the MNIST dataset from the web and perform preprocessing to prepare\n",
    "    it for the two-layer neural net classifier.\n",
    "    \"\"\"\n",
    "    # Load the raw MNIST dataset and use appropriate data types and shapes\n",
    "    mnist = tf.keras.datasets.mnist.load_data()\n",
    "    (X_train, y_train), (X_test, y_test) = mnist\n",
    "    X_train = np.asarray(X_train, dtype=np.float32)\n",
    "    y_train = np.asarray(y_train, dtype=np.int32).flatten()\n",
    "    X_test = np.asarray(X_test, dtype=np.float32)\n",
    "    y_test = np.asarray(y_test, dtype=np.int32).flatten()\n",
    "\n",
    "    # Subsample the data\n",
    "    mask = range(num_training, num_training + num_validation)\n",
    "    X_val = X_train[mask]\n",
    "    y_val = y_train[mask]\n",
    "    mask = range(num_training)\n",
    "    X_train = X_train[mask]\n",
    "    y_train = y_train[mask]\n",
    "    mask = range(num_test)\n",
    "    X_test = X_test[mask]\n",
    "    y_test = y_test[mask]\n",
    "\n",
    "    # Normalize the data: subtract the mean pixel and divide by std\n",
    "    mean_pixel = X_train.mean(axis=(0, 1, 2), keepdims=True)\n",
    "    std_pixel = X_train.std(axis=(0, 1, 2), keepdims=True)\n",
    "    X_train = (X_train - mean_pixel) / std_pixel\n",
    "    X_val = (X_val - mean_pixel) / std_pixel\n",
    "    X_test = (X_test - mean_pixel) / std_pixel\n",
    "\n",
    "    return X_train, y_train, X_val, y_val, X_test, y_test\n",
    "\n",
    "# If there are errors with SSL downloading involving self-signed certificates,\n",
    "# it may be that your Python version was recently installed on the current machine.\n",
    "# See: https://github.com/tensorflow/tensorflow/issues/10779\n",
    "# To fix, run the command: /Applications/Python\\ 3.7/Install\\ Certificates.command\n",
    "#   ...replacing paths as necessary.\n",
    "\n",
    "# Invoke the above function to get our data.\n",
    "NHW = (0, 1, 2)\n",
    "X_train, y_train, X_val, y_val, X_test, y_test = load_mnist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notar los siguientes aspectos de la función `load_mnist()`:\n",
    "\n",
    "* Separa una proporción `num_validation` de los datos de entrenamiento para utilizar como datos de validación\n",
    "* Tanto los datos de Train, Val como Test son normalizados utilizando la media (`mean_pixel`) y la desviación estandar (`std_pixel`) de los valores de los pixeles en la imagen. Se sabe que esto ayuda a las Redes Neuronales a obtener mejores resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zVau1cjqNZI_",
    "tags": [
     "pdf-ignore"
    ]
   },
   "outputs": [],
   "source": [
    "class Dataset(object):\n",
    "    def __init__(self, X, y, batch_size, shuffle=False):\n",
    "        \"\"\"\n",
    "        Construct a Dataset object to iterate over data X and labels y\n",
    "        \n",
    "        Inputs:\n",
    "        - X: Numpy array of data, of any shape\n",
    "        - y: Numpy array of labels, of any shape but with y.shape[0] == X.shape[0]\n",
    "        - batch_size: Integer giving number of elements per minibatch\n",
    "        - shuffle: (optional) Boolean, whether to shuffle the data on each epoch\n",
    "        \"\"\"\n",
    "        assert X.shape[0] == y.shape[0], 'Got different numbers of data and labels'\n",
    "        self.X, self.y = X, y\n",
    "        self.batch_size, self.shuffle = batch_size, shuffle\n",
    "\n",
    "    def __iter__(self):\n",
    "        N, B = self.X.shape[0], self.batch_size\n",
    "        idxs = np.arange(N)\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(idxs)\n",
    "        return iter((self.X[i:i+B], self.y[i:i+B]) for i in range(0, N, B))\n",
    "\n",
    "\n",
    "train_dset = Dataset(X_train, y_train, batch_size=64, shuffle=True)\n",
    "val_dset = Dataset(X_val, y_val, batch_size=64, shuffle=False)\n",
    "test_dset = Dataset(X_test, y_test, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_uFB4rXsNZJA"
   },
   "outputs": [],
   "source": [
    "# We can iterate through a dataset like this:\n",
    "for t, (x, y) in enumerate(train_dset):\n",
    "    print(t, x.shape, y.shape)\n",
    "    if t > 5: break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mw18cy_-NZJB"
   },
   "source": [
    "Opcionalmente puedes **usasr GPU seteando la siguiente flag en True** en la siguiente celda.\n",
    "\n",
    "## Usuarios Colab\n",
    "\n",
    "Si estas usando Colab, seguramente necesites manualmente cambiar a un entorno GPU. La forma de hacer esto es clickeando la opcion `Runtime -> Change runtime type` y seleccionar la opción `GPU` dentro de `Hardware Accelerator`. Notar que debes correr de nuevo todas las celdas de arriba ya que al cambiar de entorno de ejecución el kernel del notebook se reinicia perdiendo el estado actual."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ERiu2miJNZJB",
    "tags": [
     "pdf-ignore-input"
    ]
   },
   "outputs": [],
   "source": [
    "# Set up some global variables\n",
    "USE_GPU = True\n",
    "\n",
    "if USE_GPU:\n",
    "    device = '/device:GPU:0'\n",
    "else:\n",
    "    device = '/cpu:0'\n",
    "\n",
    "# Constant to control how often we print when training models\n",
    "print_every = 100\n",
    "\n",
    "print('Using device: ', device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parte II: Entendimiento de los datos\n",
    "\n",
    "En segundo lugar echemos un vistaso a las imágnes con las que vamos a trabajar el resto del notebook para entender cuantos datos tenemos para trabajar y preveer cualquier potencial problema antes de entrenar cualquier modelo.\n",
    "\n",
    "En un dataset compuesto por imágenes y en particular en la tarea de clasificación usualmente se chequean los siguientes puntos antes de empezar a entrenar un modelo:\n",
    "\n",
    "* ¿Cuántas imágenes tenemos para Train y cuántas para Test?\n",
    "* ¿Cuántas imágenes tenemos por cada clase, está balanceado?\n",
    "* ¿Qué resolución tiene cada imagen? ¿Son todas iguales o hay que aplicar algún re-size?\n",
    "* ¿Cuantos canales tiene la imágen (blanco y negro o a color)?\n",
    "\n",
    "Además, es una buena práctica visualizar algunas imágenes por cada clase, para comprender bien como son las imágenes con las que estaremos trabajando.\n",
    "\n",
    "Empecemos entonces a contestar estas preguntas!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**¿Cuántas imágenes tenemos?**\n",
    "\n",
    "Veamos algunas estadísticas generales del dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print some basic stats about the dataset\n",
    "print('Train data shape: ', X_train.shape)\n",
    "print('Train labels shape: ', y_train.shape, y_train.dtype)\n",
    "print('Validation data shape: ', X_val.shape)\n",
    "print('Validation labels shape: ', y_val.shape)\n",
    "print('Test data shape: ', X_test.shape)\n",
    "print('Test labels shape: ', y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**¿Cuántas imágenes tenemos por cada clase?**\n",
    "\n",
    "Como se puede ver en las celdas a continuación, si bien el dataset no contiene exactamente la misma cantidad de ejemplos para cada clase, se puede decir que está balanceado, contando con al menos 5200 ejemplos para cada clase y a lo sumo 6500. \n",
    "\n",
    "Se puede decir entonces que al menos en cantidad, es un dataset suficiente para comenzar a trabajar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute unique values on y_train\n",
    "unique, counts = np.unique(y_train, return_counts=True)\n",
    "\n",
    "print(dict(zip(unique, counts)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Display as bar plot\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_axes([0,0,1,1])\n",
    "ax.bar(unique, counts)\n",
    "\n",
    "plt.xticks(unique)  # To display each value of\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**¿Que sucede con el dataset de test?** Como se puede ver en la figura debajo, también se encuentra balanceado, con cerca de 1000 ejemplos por clase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################################\n",
    "# TODO: Calcular cantidad de ejemplos por clase en y_test y graficar       #\n",
    "############################################################################\n",
    "# *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "\n",
    "pass\n",
    "\n",
    "# *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "############################################################################\n",
    "#                            END OF YOUR CODE                              #\n",
    "############################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**¿Qué resolución tiene cada imagen?**\n",
    "\n",
    "Como se puede ver debajo, el dataset de entrenamiento se compone de 58.000 imágnes de 28x28 pixeles. En este caso entonces no tenemos nada de que preocuparnos, todas las imágenes tienen la misma resolución. En otros datasets con los que aveces trabajamos esto no sucede, por lo que es necesario aplicar un paso de re-size en todas las imágenes antes de continuar trabajando, para algunas arquitecturas de redes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Entendiendo las imágenes**\n",
    "\n",
    "Como se puede ver a continuación, cada imágen contiene un solo dígito en blanco y negro. A este tipo de imágenes se las conoce como máscaras binarias también, ya que contiene en color blanco solo los pixeles que pertenecen al objeto en cuestión (en este caso un dígito) y en negro aquellos pixeles que pertenecen al fondo de la imágen.\n",
    "\n",
    "En deep learning se suelen trabajar con imágenes a color y en blanco y negro como es este caso. Cuando las imágenes son en blanco y negro comoe este caso, se dice que la imagen tiene un solo canal (1 o cero). En caso que la imagen sea a color se suele trabajar con el sistema RGB, por lo que se dice que la imagen tiene 3 canales. En este caso, notar que la matriz que representa la imagen ya no sería de 28x28 pixeles.\n",
    "\n",
    "_¿Qué dimensión tendría?\n",
    "HINT: Pensar en el color de cada pixel representado por el sistema RGB._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_mnist_images(X, y, num=25, num_row=5, num_col=5):\n",
    "    \"\"\"\n",
    "    Display on a grid using matplotlib train images and their corresponding\n",
    "    label.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Get images to display\n",
    "    images = X[:num]\n",
    "    labels = y[:num]\n",
    "\n",
    "    # plot images\n",
    "    fig, axes = plt.subplots(num_row, num_col, figsize=(1.5*num_col,2*num_row))\n",
    "    for i in range(num):\n",
    "        ax = axes[i//num_col, i%num_col]\n",
    "        ax.imshow(images[i], cmap='gray')\n",
    "        ax.set_title('Label: {}'.format(labels[i]))\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "display_mnist_images(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parte III: Entrenamiento\n",
    "\n",
    "Ahora que tenemos un mejor entendimiento del problema y las imágenes con las que contamos, pasemos a definir y entrenar el modelo que clasifique las imágenes.\n",
    "\n",
    "Para esto vamos a utilizar la clase `tf.keras.Sequential` disponible en la libreria Keras, que permite definir una red neuronal con un número arbitrario de `layers`. Por más información acerca de esta clase leer [tf.keras.Sequential](https://www.tensorflow.org/api_docs/python/tf/keras/Sequential) la documentación.\n",
    "\n",
    "Para entrar en calentamiento lo que vamos a hacer, es definir una sencilla Red Neuronal con 1 hidden layer y Relu como función de activación.\n",
    "\n",
    "Resumen:\n",
    "* Input Layer: Imágenes de 28x28 como vector usando la clase [tf.keras.layers.Flatten](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Flatten) que toma una matrix de cualquier tamaño y la convierte en un vector.\n",
    "* Hidden Layer: Capa oculta de 128 neuronas con Relu. Leer más sobre [tf.keras.layers.Dense](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dense).\n",
    "* Output Layer: Nuevamente usamos `tf.keras.layers.Dense` pero con largo 10 (por 10 diferentes clases)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model architecture using keras.Sequential API\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(28, 28)),  # Flatten of img input size\n",
    "    tf.keras.layers.Dense(128, activation='relu'),  # Dense of arbitrary hidden neurons size\n",
    "    tf.keras.layers.Dense(10)  # Dense of num_classes length\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez definida la arquitectura del modelo es necesario compilarlo, indicando entre otras clases optimizador a utilizar para el entrenamiento, que función de costo vamos a utilizar y la métrica de evaluación. Leer más acerca de [tf.keras.compile](https://www.tensorflow.org/api_docs/python/tf/keras/Model). \n",
    "\n",
    "En este caso vamos a utilizar:\n",
    "* Optimizador: SGD con momentum. Leer más en [keras optimizers](https://www.tensorflow.org/api_docs/python/tf/keras/optimizers).\n",
    "* `SparseCategoricalCrossentropy`: Entropía cruzada comunmente utilizada como función de costo en problemas de clasificación. Leer más en [SparseCategoricalCrossentropy](https://www.tensorflow.org/api_docs/python/tf/keras/losses/SparseCategoricalCrossentropy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model\n",
    "model.compile(optimizer='SGD',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora solo resta entrenar el modelo tantas `epochs` como creamos conveniente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model\n",
    "model.fit(X_train, y_train, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parte IV: Evaluación\n",
    "\n",
    "Como podemos ver del loss log durante el entrenamiento, con esta simple arquitectura se puede sobre-ajustar los datos de entrenamiento, logrando un `loss < 0.03` y una `accuracy` superior al `0.99`.\n",
    "\n",
    "Sin embargo, no siempre los resultados en la fase de Train se asemejan a los resultados sobre datos reales o en este caso, sobre los datos que separamos para Test. Por ello, veamos como nos va con la `accuracy` sobre los datos de Test.\n",
    "\n",
    "Para ello vamos a utilizar la función `evaluate` de la propia clase `keras.Model`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_loss, test_acc = model.evaluate(X_test,  y_test, verbose=2)\n",
    "\n",
    "print('\\nTest accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test con imagen arbitraria\n",
    "\n",
    "Veamos como interactuar con el modelo para predecir el resultado de una imagen arbitraria en el dataset de test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change num_sample to test with a different image\n",
    "num_sample = 50\n",
    "image = X_test[num_sample]\n",
    "label = y_test[num_sample]\n",
    "\n",
    "plt.imshow(image, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Next cell call model using predict method. Recall in the fact model expects to recive an array of \n",
    "# examples instead of a single example. For this reason is neccesary to expand dims of image to an array with a\n",
    "# single image.\n",
    "# For the same reason predictions is a list of predictions\n",
    "predictions = model.predict(np.expand_dims(image, axis=0)) \n",
    "\n",
    "prediction = np.argmax(predictions[0])  # prediction is an array of 10 probabilities, the highest is the predicted class\n",
    "\n",
    "print(f\"Prediction: {prediction} and expected is: {label}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parte IV: Experimentación"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora que tenemos claro como definir una arquitectura de Red Neuronal con Keras y entranarla, te proponemos que  pruebes algunas varianetes del modelo original para ver si es posible mejorar la `accuracy` sobre los datos de Test y llegar a un valor similar al `0.99` obtenido sobre los datos de Train.\n",
    "\n",
    "A modo de guia te sugerimos algunas de las siguientes variantes para probar:\n",
    "\n",
    "* Cambios en arquitectura: Cambiar el número de neuronas en la capa oculta (Dense) para incrementar / decrementar la capacidad del modelo.\n",
    "* Optimizadores: En el modelo original se utiliza SGD (Stochastic gradient descent), probar con otros optimizadores como [RMSprop o Adam](https://www.tensorflow.org/api_docs/python/tf/keras/optimizers).\n",
    "* Dropout: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################################\n",
    "# TODO: Calcular cantidad de ejemplos por clase en y_test y graficar       #\n",
    "############################################################################\n",
    "# *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    ...  # TODO: Edit this\n",
    "])\n",
    "\n",
    "# *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "############################################################################\n",
    "#                            END OF YOUR CODE                              #\n",
    "############################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################################\n",
    "# TODO: Calcular cantidad de ejemplos por clase en y_test y graficar       #\n",
    "############################################################################\n",
    "# *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "\n",
    "model.compile(optimizer=pass,  # TODO: Select an optimizer\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "############################################################################\n",
    "#                            END OF YOUR CODE                              #\n",
    "############################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################################\n",
    "# TODO: Calcular cantidad de ejemplos por clase en y_test y graficar       #\n",
    "############################################################################\n",
    "# *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "\n",
    "model.fit(X_train, y_train, epochs=pass)  # TODO: select num of epochs\n",
    "\n",
    "# *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "############################################################################\n",
    "#                            END OF YOUR CODE                              #\n",
    "############################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_acc = model.evaluate(X_test,  y_test, verbose=2)\n",
    "\n",
    "print('\\nTest accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Me siento curioso**:\n",
    "\n",
    "Si te sientes curioso acerca de como ir más allá del 99% de accuracy sobre MNIST y no lograste dar con la respuesta te recomiendo continuar tu investigación [aquí](https://towardsdatascience.com/going-beyond-99-mnist-handwritten-digits-recognition-cfff96337392)."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "jQoe9j1NNZJE",
    "_1NFrad8NZJH",
    "F-mxR_zwNZJJ",
    "DKnxzfcLNZJK",
    "hsLhpkJKNZJK",
    "yKQJd15tNZJL",
    "2BISVc6PNZJM",
    "g_F27n_DNZJM",
    "xDILipvANZJN",
    "T0DJFYfxNZJN",
    "iDCugysaNZJO",
    "vnQn-JwuNZJO",
    "B9P-0psbNZJP"
   ],
   "name": "TensorFlow.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
