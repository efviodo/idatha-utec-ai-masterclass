{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lt0srYHUNZIz",
    "tags": [
     "pdf-title"
    ]
   },
   "source": [
    "# Computer Vision CIFAR-10\n",
    "\n",
    "En este notebook continuaremos profundizando en las funcionalidades de Keras y Tensorflow, para entrenar Redes Neuronales Convolucionales y resolver problemas de clasificación más complejos. En particualr vamos a resolver el problema de clasificación de imágenes en el dataset CIFAR-10."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7DkxZtF3NZI6",
    "tags": [
     "pdf-ignore"
    ]
   },
   "source": [
    "# Tabla de Contenidos\n",
    "\n",
    "Este notebook contiene 5 partes. Vamos a repasar algunas funcionalidades básicas de TensorFlow y Keras entrenando un modelo para reconocer dígitos escritos a mano.\n",
    "\n",
    "1. Parte I, Preparación: cargar dataset CIFAR-10.\n",
    "2. Parte II, Entendimiento: visualizar datos y obtener algunas estadísticas.\n",
    "3. Parte III, Entrenamiento: definición y entrenamiento de una Red Convolucional.\n",
    "4. Parte IV, Evaluación: evaluar el modelo y predecir algunos casos.\n",
    "4. Parte V, Experimentación"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TxYL1sA5NZI7"
   },
   "source": [
    "# Parte I: Preparación\n",
    "\n",
    "Primero, vamos a descargar el dataset CIFAR10. Esto puede tomar algunos minutos para descargar los datos por primer vez, pero luego de que los archivos son descargados y cacheados en disco la carga debería ser más rápida.\n",
    "\n",
    "Al igual que en el notebook anterior y por simplicidad, vamos a trabajar con el módulo ```tf.keras.datasets``` que ya provee utilidades para cargar y trabajar con este dataset entre otros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tTfjivr-NZI8",
    "tags": [
     "pdf-ignore"
    ]
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import math\n",
    "import timeit\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_cifar10(num_training=48000, num_validation=2000, num_test=10000):\n",
    "    \"\"\"\n",
    "    Fetch the CIFAR-10 dataset from the web and perform preprocessing to prepare\n",
    "    it for the two-layer neural net classifier.\n",
    "    \"\"\"\n",
    "    # Load the raw CIFAR-10 dataset and use appropriate data types and shapes\n",
    "    cifar10 = tf.keras.datasets.cifar10.load_data()\n",
    "    (X_train, y_train), (X_test, y_test) = cifar10\n",
    "    \n",
    "    # Subsample the data\n",
    "    mask = range(num_training, num_training + num_validation)\n",
    "    X_val = X_train[mask]\n",
    "    y_val = y_train[mask]\n",
    "    mask = range(num_training)\n",
    "    X_train = X_train[mask]\n",
    "    y_train = y_train[mask]\n",
    "    mask = range(num_test)\n",
    "    X_test = X_test[mask]\n",
    "    y_test = y_test[mask]\n",
    "\n",
    "    return X_train, y_train, X_val, y_val, X_test, y_test\n",
    "\n",
    "# If there are errors with SSL downloading involving self-signed certificates,\n",
    "# it may be that your Python version was recently installed on the current machine.\n",
    "# See: https://github.com/tensorflow/tensorflow/issues/10779\n",
    "# To fix, run the command: /Applications/Python\\ 3.7/Install\\ Certificates.command\n",
    "#   ...replacing paths as necessary.\n",
    "\n",
    "# Invoke the above function to get our data.\n",
    "NHW = (0, 1, 2)\n",
    "X_train, y_train, X_val, y_val, X_test, y_test = load_cifar10()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mw18cy_-NZJB"
   },
   "source": [
    "Opcionalmente puedes **usasr GPU seteando la siguiente flag en True** en la siguiente celda.\n",
    "\n",
    "## Usuarios Colab\n",
    "\n",
    "Si estas usando Colab, seguramente necesites manualmente cambiar a un entorno GPU. La forma de hacer esto es clickeando la opcion `Runtime -> Change runtime type` y seleccionar la opción `GPU` dentro de `Hardware Accelerator`. Notar que debes correr de nuevo todas las celdas de arriba ya que al cambiar de entorno de ejecución el kernel del notebook se reinicia perdiendo el estado actual."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ERiu2miJNZJB",
    "tags": [
     "pdf-ignore-input"
    ]
   },
   "outputs": [],
   "source": [
    "# Set up some global variables\n",
    "USE_GPU = True\n",
    "\n",
    "if USE_GPU:\n",
    "    device = '/device:GPU:0'\n",
    "else:\n",
    "    device = '/cpu:0'\n",
    "\n",
    "# Constant to control how often we print when training models\n",
    "print_every = 100\n",
    "\n",
    "print('Using device: ', device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parte II: Entendimiento de los datos\n",
    "\n",
    "Recordemos algunas de las preguntas que nos solemos hacer antes de empezara a trabajar con un set de datos de entrenamiento: \n",
    "\n",
    "* ¿Cuántas imágenes tenemos para Train y cuántas para Test?\n",
    "* ¿Cuántas imágenes tenemos por cada clase, está balanceado?\n",
    "* ¿Qué resolución tiene cada imagen? ¿Son todas iguales o hay que aplicar algún re-size?\n",
    "* ¿Cuantos canales tiene la imágen (blanco y negro o a color)?\n",
    "\n",
    "Además, es una buena práctica visualizar algunas imágenes por cada clase, para comprender bien como son las imágenes con las que estaremos trabajando.\n",
    "\n",
    "Empecemos entonces a contestar estas preguntas!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**¿Cuántas imágenes tenemos?**\n",
    "\n",
    "Veamos algunas estadísticas generales del dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print some basic stats about the dataset\n",
    "print('Train data shape: ', X_train.shape)\n",
    "print('Train labels shape: ', y_train.shape, y_train.dtype)\n",
    "print('Validation data shape: ', X_val.shape)\n",
    "print('Validation labels shape: ', y_val.shape)\n",
    "print('Test data shape: ', X_test.shape)\n",
    "print('Test labels shape: ', y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**¿Cuántas imágenes tenemos por cada clase?** Complete la celda a continuación par verificar si los datos de entrenamiento (y_train) se encuentran balanceados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################################\n",
    "# TODO: Calcular cantidad de ejemplos por clase en y_train y graficar       #\n",
    "############################################################################\n",
    "# *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "\n",
    "pass\n",
    "\n",
    "# *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "############################################################################\n",
    "#                            END OF YOUR CODE                              #\n",
    "############################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**¿Que sucede con el dataset de test?** Complete la celda a continuación para verificar si los datos de prueba (y_test) se encuentran balanceados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################################\n",
    "# TODO: Calcular cantidad de ejemplos por clase en y_test y graficar       #\n",
    "############################################################################\n",
    "# *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "\n",
    "pass\n",
    "\n",
    "# *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "############################################################################\n",
    "#                            END OF YOUR CODE                              #\n",
    "############################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**¿Qué resolución tiene cada imagen?**\n",
    "\n",
    "El dataset de entrenamiento se compone de **50.000** imágenes de una misma resolución para facilitar el trabajo de entrenamiento. Para corroborar esto se puede revisar las dimensiones de la matrix que contiene los datos de entrenamiento, es decir, las dimensiones de `X_train`. \n",
    "\n",
    "_HINT: Recuerde que toda matrix de `numpy` cuenta con el atributo `shape` que describe sus dimensiones._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################################\n",
    "# TODO: Revisar la resolución de una imagen de entrenamiento               #\n",
    "############################################################################\n",
    "# *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "\n",
    "pass\n",
    "\n",
    "# *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "############################################################################\n",
    "#                            END OF YOUR CODE                              #\n",
    "############################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Entendiendo las imágenes**\n",
    "\n",
    "A continuación vamos a ver de que se tratan las imágenes de CIFAR-10 y para ello vamos a utilizar las misma estrategia que con MNIST: matplotlib. Notese además, a diferencia de MNIST, que en CIFAR-10 las imágenes son a color por lo que tenemos 3 canales extra en las imágenes: RGB.\n",
    "\n",
    "Por otro lado, en MNIST las imágenes se correspondian a los números 0,1, 2, ... , 9 y sus etiquetas coincidían con el dígito en cuestión. En este caso, las etiquetas son: \"airplane\", \"automobile\", ..., \"truck\". Sin embargo, por simplicidad también se codifican con números del 0 al 9 (en este caso porque tenemos 10 clases). Por ello, será necesario definirnos un diccionario para mapear de los respectivos números en las etiquetas a su clase, para facilitar la interpretación de los resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Maps label number to class name\n",
    "\n",
    "idx_to_label = {\n",
    "    0: \"airplane\",\n",
    "    1: \"automobile\",\n",
    "    2: \"bird\",\n",
    "    3: \"cat\",\n",
    "    4: \"deer\",\n",
    "    5: \"dog\",\n",
    "    6: \"frog\",\n",
    "    7: \"horse\",\n",
    "    8: \"ship\",\n",
    "    9: \"truck\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def display_cifar10_images(X, y, num=25, num_row=5, num_col=5):\n",
    "    \"\"\"\n",
    "    Display on a grid using matplotlib train images and their corresponding\n",
    "    label.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Get images to display\n",
    "    images = X[:num]\n",
    "    labels = y[:num]\n",
    "\n",
    "    # plot images\n",
    "    fig, axes = plt.subplots(num_row, num_col, figsize=(1.5*num_col,2*num_row))\n",
    "    for i in range(num):\n",
    "        ax = axes[i//num_col, i%num_col]\n",
    "        ax.imshow(images[i])\n",
    "        ax.set_title('Label: {}'.format(idx_to_label[labels[i][0]]))\n",
    "        \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "display_cifar10_images(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a ver una forma diferente de normalizar las fotos. Mientras que en el notebook anterior normalizabamos cada pixel de una foto teniendo en cuenta la media y desviación estandard en el dataset, en este caso simplemente vamos a llevar el valor de un pixel al intervalo [0 ... 1]. Esto es porque las Redes Neuronales realizan las operaciones de forma más eficiente con números en este rango."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_images(X_train, X_test):\n",
    "    \"\"\"\n",
    "    This function scales each image to range 0-1 for simplicity for\n",
    "    neural networks.\n",
    "    \"\"\"\n",
    "    \n",
    "    ############################################################################\n",
    "    # TODO: Revisar la resolución de una imagen de entrenamiento               #\n",
    "    ############################################################################\n",
    "    # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "\n",
    "\n",
    "    # convert from integers to floats\n",
    "    train_norm = X_train.astype('float32')\n",
    "    test_norm = X_test.astype('float32')\n",
    "    \n",
    "    # normalize to range 0-1\n",
    "    train_norm = pass / 255  # TODO: Normalize each pixel in range 0-255\n",
    "    test_norm = pass / 255  # TODO: Normalize each pixel in range 0-255 \n",
    "    \n",
    "    # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "    ############################################################################\n",
    "    #                            END OF YOUR CODE                              #\n",
    "    ############################################################################\n",
    "\n",
    "    return train_norm, test_norm\n",
    "\n",
    "X_train, X_test = scale_images(X_train, X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parte III: Entrenamiento\n",
    "\n",
    "Ahora que tenemos un mejor entendimiento del problema y las imágenes con las que contamos, pasemos a definir y entrenar el modelo que clasifique las imágenes.\n",
    "\n",
    "Para esto vamos a utilizar la clase `tf.keras.Sequential` disponible en la libreria Keras, que permite definir una red neuronal con un número arbitrario de `layers`. Por más información acerca de esta clase leer [tf.keras.Sequential](https://www.tensorflow.org/api_docs/python/tf/keras/Sequential) la documentación.\n",
    "\n",
    "Para entrar en calentamiento lo que vamos a hacer, es definir una sencilla Red Neuronal utilizando convoluciones y finalmente una capa densamente conectada. \n",
    "\n",
    "Resumen de la arquitectura:\n",
    "* Input Layer: Imágenes de 32x32 que como son el input de una convolución no las vamos a aplanar como vector aun. \n",
    "* Conv2D: Capa de convolución con 16 filtros de 3x3 y Relu. Leer más en [tf.keras.layers.Conv2D](https://keras.io/api/layers/convolution_layers/convolution2d/).\n",
    "* Conv2D: Capa de convolución de 32 filtros de 3x3.\n",
    "* Flatten: Pasamos a vector. Leer más en [tf.keras.layers.Flatten](https://keras.io/api/layers/reshaping_layers/flatten/).\n",
    "* Hidden Layer: Capa oculta de 64 neuronas con Relu. Leer más sobre [tf.keras.layers.Dense](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dense).\n",
    "* Output Layer: Nuevamente usamos `tf.keras.layers.Dense` pero con largo 10 (por 10 diferentes clases)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model architecture using keras.Sequential API\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.Input(shape=(32, 32, 3)),\n",
    "    tf.keras.layers.Conv2D(16, kernel_size=(3, 3), activation=\"relu\"),  # 32 blocks of CONV2D\n",
    "    tf.keras.layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\"),  # 64 blocks of CONV2D\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(10)  # Dense of num_classes length\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compilación:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model\n",
    "model.compile(optimizer='SGD',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model\n",
    "model.fit(X_train, y_train, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parte IV: Evaluación\n",
    "\n",
    "A diferencia del MNIST, este es un problema más complejo de resolver por lo que no es de esperar lograr resultados muy buenos con la arquitectura simple definida arriba. De hecho, entrenando esa misma arquitectura, se debería alcanzar una `loss ~ 1.065` y una `accuracy` en el entorno de `0.629` sobre los datos de Test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_loss, test_acc = model.evaluate(X_test,  y_test, verbose=2)\n",
    "\n",
    "print('\\nTest accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test con imagen arbitraria\n",
    "\n",
    "Veamos que tan bien nos va con una imagen cualquiera del dataset de Test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change num_sample to test with a different image\n",
    "num_sample = 12\n",
    "image = X_test[num_sample]\n",
    "label = y_test[num_sample]\n",
    "\n",
    "plt.imshow(image)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "predictions = model.predict(np.expand_dims(image, axis=0)) \n",
    "prediction = np.argmax(predictions[0])  # prediction is an array of 10 probabilities, the highest is the predicted class\n",
    "\n",
    "print(f\"Prediction: {idx_to_label[prediction]} and expected is: {idx_to_label[label[0]]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parte IV: Experimentación"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora que tenemos claro como definir Redes Neuronales Convolucionales y su poder, te toca el turno a ti de jugar con diferentes opciones de arquitecturas para alcanzar una mejor accuracy sobre los datos de Test.\n",
    "\n",
    "A modo de guia te sugerimos algunas de las siguientes variantes para probar:\n",
    "\n",
    "* Agregar layers de convolución: Agregar más capas Conv2D y con mayor profundidad (32, 64, 128).\n",
    "* Probar intercalar layers de convolución con Max Pooling.  Leer más en [tf.keras.layers.MaxPooling2D](https://keras.io/api/layers/pooling_layers/max_pooling2d/).\n",
    "* Probar varias layers densas al final para incrementar capacidad del modelo.\n",
    "* Optimizadores: En el modelo original se utiliza SGD (Stochastic gradient descent), probar con otros optimizadores como [RMSprop o Adam](https://www.tensorflow.org/api_docs/python/tf/keras/optimizers).\n",
    "* Dropout: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Dropout: Para evitar sobreajuste. Leer más en [tf.keras.layers.Dropout](https://keras.io/api/layers/regularization_layers/dropout/).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################################\n",
    "# TODO: Calcular cantidad de ejemplos por clase en y_test y graficar       #\n",
    "############################################################################\n",
    "# *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    ...  # TODO: Edit this\n",
    "])\n",
    "\n",
    "# *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "############################################################################\n",
    "#                            END OF YOUR CODE                              #\n",
    "############################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################################\n",
    "# TODO: Calcular cantidad de ejemplos por clase en y_test y graficar       #\n",
    "############################################################################\n",
    "# *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "\n",
    "model.compile(optimizer=pass,  # TODO: Select an optimizer\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "############################################################################\n",
    "#                            END OF YOUR CODE                              #\n",
    "############################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################################\n",
    "# TODO: Calcular cantidad de ejemplos por clase en y_test y graficar       #\n",
    "############################################################################\n",
    "# *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "\n",
    "model.fit(X_train, y_train, epochs=pass)  # TODO: select num of epochs\n",
    "\n",
    "# *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "############################################################################\n",
    "#                            END OF YOUR CODE                              #\n",
    "############################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_acc = model.evaluate(X_test,  y_test, verbose=2)\n",
    "\n",
    "print('\\nTest accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un método usualmente útil para diagnosticar si el entrenamiento de un modelo es correcto, es graficar la evolución de alguna de las métricas de evaluación del modelo como la `accuracy` o la `loss` a través de las `epochs`. Además comparar la misma métrica en el dataset de Train y Validation.\n",
    "\n",
    "Veamos a continuación como podemos hacer esto utilizando `matplotlib` y los valores que el propio método `fit` de TensorFlow nos da.\n",
    "\n",
    "1. Primero tenemos que cambiar la linea de entrenamiento por lo siguiente, para guardar el histórico de valores de las métricas a evaluar.\n",
    "\n",
    "```\n",
    "history = model.fit(X_train, y_train, batch_size=64, epochs=10, validation_data=(X_val, y_val))\n",
    "```\n",
    "\n",
    "2. Luego, utilizamos la información en history para construír gráficos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X_train, y_train, batch_size=64, epochs=10, validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot diagnostic learning curves\n",
    "def summarize_diagnostics(history):\n",
    "    # plot loss\n",
    "    plt.subplot(211)\n",
    "    plt.title('Cross Entropy Loss')\n",
    "    plt.plot(history.history['loss'], color='blue', label='train')\n",
    "    plt.plot(history.history['val_loss'], color='orange', label='test')\n",
    "    # plot accuracy\n",
    "    plt.subplot(212)\n",
    "    plt.title('Classification Accuracy')\n",
    "    plt.plot(history.history['accuracy'], color='blue', label='train')\n",
    "    plt.plot(history.history['val_accuracy'], color='orange', label='test')\n",
    "    \n",
    "summarize_diagnostics(history)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "jQoe9j1NNZJE",
    "_1NFrad8NZJH",
    "F-mxR_zwNZJJ",
    "DKnxzfcLNZJK",
    "hsLhpkJKNZJK",
    "yKQJd15tNZJL",
    "2BISVc6PNZJM",
    "g_F27n_DNZJM",
    "xDILipvANZJN",
    "T0DJFYfxNZJN",
    "iDCugysaNZJO",
    "vnQn-JwuNZJO",
    "B9P-0psbNZJP"
   ],
   "name": "TensorFlow.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
